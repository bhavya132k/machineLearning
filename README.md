# **Introduction**
Welcome to my GitHub repository, where I showcase a collection of my machine learning course projects and personal hobby projects. This repository serves as a portfolio of my data science and machine learning work, as well as a glimpse into my creative side through various hobby projects.

# **Project 1**

## **Machine Learning from Scratch: Kaggle Most Streamed Spotify Songs 2023**

### **Objective**

The objective of this project is to implement a machine learning algorithm
from scratch using the ”Most Streamed Spotify Songs 2023”. You are required
to use first principle functions and are allowed to use tools such as numpy
and pandas for data manipulation, but not any machine learning packages
such as sklearn, pytorch, tensorflow, etc.

### **Dataset**

Link: https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023
The dataset contains several features about songs in the Spotify library. Your task is to predict a target variable using the features provided in the dataset. The target variable in this dataset could be the "streams" of the song, which represents the total number of streams on Spotify.

### **Components**

1. Data Preprocessing
2. Implement a Machine Learning Algorithm
3. Model Evaluation
4. Report


# **Project 2**

## **Binary Classification with Custom Naive Bayes**

### **Objective**

The objective of this Project is to develop a binary classification model using the Naive Bayes algorithm. Students will gain hands-on experience in data loading, preprocessing, visualization, and model evaluation, applying statistical fundamentals to create an effective classifier.

### **Dataset**

The dataset to be used for this Project is available in this repository at /machineLearning/Projects/BinaryClassification/myocardial+infarction+complications.zip


### **Components**

1. Data Loading and Preprocessing
•	Load the dataset from the provided URL into a suitable data structure (like a pandas Data Frame).
•	Clean the data by handling missing values, and normalizing numerical features as needed.
•	Split the dataset into training and testing subsets to facilitate model evaluation.

2. Data Visualization
•	Generate visual plots (e.g., histograms, bar charts, box plots) to understand the distribution and characteristics of the dataset.
•	Visualize the class distribution to check for class imbalance and consider strategies like resampling if needed.

3. Binary Classification Model Development
•	Implement the Naive Bayes classifier. Document the mathematical formulation and programming logic used if you develop from scratch.
•	Optimize the model by experimenting with different techniques like feature selection and hyperparameter tuning.

4. Code Implementation and Testing
•	Write clean, modular, and well-documented Python code for the entire classification process.
•	Test the classifier on the test set and ensure your code produces reliable outputs.

5. Performance Analysis
•	Evaluate the classifier using metrics such as accuracy, precision, recall, F1 score, and ROC curve.
•	Draw a confusion matrix to understand true positives, true negatives, false positives, and false negatives.

6. Reflection and Insights: 
•	Reflect on the performance of the Naive Bayes classifier, providing an analysis of the results.
•	Discuss any observed limitations and propose potential improvements or future work that could enhance the classifier's performance.

 

# **Project 3**

## **Emotion Analysis using SVM and K-Means Clustering**

### **Objective**

Develop an understanding of emotion recognition in text using Support Vector Machines (SVM) for classification and K-Means clustering for pattern discovery. This Project will help you grasp the nuances of supervised and unsupervised learning techniques in Natural Language Processing (NLP).

### **Dataset**
The dataset to be used is the EmotionLines dataset, which can be found in this repository at /machineLearning/Projects/EmotionAnalysis/EmotionLines/Friends


### **Components**

1. Data Preparation:
•	Load and familiarize yourself with the EmotionLines dataset.
•	Conduct text preprocessing: tokenize, stem/lemmatize, and remove stop words.
•	Transform text into numerical representations using TF-IDF.

2. SVM for Emotion Classification:
•	Construct an SVM classifier to categorize emotions in text data.
•	Optimize the classifier by experimenting with different kernels and hyperparameters.
•	Validate the model using cross-validation and compute classification metrics.

3. K-Means Clustering:
•	Implement K-Means clustering on the preprocessed text data.
•	Identify the optimal number of clusters with methods like the elbow technique.
•	Interpret the clusters to find patterns corresponding to different emotions.

3. Model Insights:
•	Analyze the performance of the SVM classifier and the clusters formed by K-Means.
•	Compare and contrast the results obtained from both SVM and K-Means.
•	Offer insights into the emotional trends captured by the models.

4. Report and Documentation:
•	Document your process, code, and results in a clear and structured  report.
•	Reflect on the classifier’s performance and the clustering outcomes.
•	Suggest improvements and real-world applications of your findings.


